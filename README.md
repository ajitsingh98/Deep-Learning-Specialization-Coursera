# Deep Learning Specialization - Coursera

Instructor: [Andrew Ng](https://www.coursera.org/specializations/deep-learning/)

Introduction
---

I did this specialization in `2020` and then later I decided to implement all the assignments in `PyTorch` again instead of `TensorFlow`.

*In this comprehensive program comprising five courses, you will acquire a solid understanding of Deep Learning fundamentals. You will gain expertise in constructing neural networks and effectively leading machine learning projects. The curriculum covers a wide range of essential topics such as `Convolutional networks`, `RNNs`, `LSTM`, `Adam`, `Dropout`, `BatchNorm`, `Xavier/He initialization`, and more. Through engaging case studies drawn from diverse domains such as healthcare, autonomous driving, sign language interpretation, music generation, and natural language processing, you will apply these concepts in practical scenarios. Notably, this program not only emphasizes theoretical knowledge but also provides insights into real-world implementation.*

Contents
---

### Course 1: Neural Networks and Deep Learning

**Topics Covered**
  - [Week 1: Introduction to Deep Neural Networks]()
      + Understand the major trends driving the rise of deep learning.
      + Be able to explain how deep learning is applied to supervised learning.
      + Understand what are the major categories of models (such as CNNs and RNNs), and when they should be applied.
      + Be able to recognize the basics of when deep learning will (or will not) work well.
  - [Week 2: Basic of Neural Network Programming]()
      + Develop intuition about structure of Forward Propagation, Backward propagation and steps for algorithms and how to implement NN efficiency.
      + Build a logistic regression model, structured as a shallow neural network
      + Implement the main steps of an ML algorithm, including making predictions, derivative computation, and gradient descent.
      + Implement computationally efficient, highly vectorized, versions of models.
      + Understand how to compute derivatives for logistic regression, using a back-propagation mindset. Become familiar with Python and Numpy
      + Work with iPython Notebooks
      + Be able to implement vectorization across multiple training examples
  - [Week 3: Shallow Neural Networks]()
      + Understand hidden units and hidden layers
      + Be able to apply a variety of activation functions in a neural network.
      + Build your first forward and backward propagation with a hidden layer
      + Apply random initialization to your neural network
      + Become fluent with Deep Learning notations and Neural Network Representations
      + Build and train a neural network with one hidden layer.
  - [Week 4: Deep Neural Networks (Multiple layers)]()
      + See deep neural networks as successive blocks put one after each other
      + Build and train a deep L-layer Neural Network
      + Analyze matrix and vector dimensions to check neural network implementations.
      + Understand how to use a cache to pass information from forward propagation to back propagation.
      + Understand the role of hyperparameters in deep learning

    **Programming Assignments**

### Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

**Topics Covered**
  
  - [Week 1: Introduction to Deep Neural Networks]()
      + Recall that different types of initializations lead to different results 
      + Recognize the importance of initialization in complex neural networks. 
      + Recognize the difference between train/dev/test sets
      + Diagnose the bias and variance issues in your model
      + Learn when and how to use regularization methods such as dropout or L2 regularization.
      + Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them
      + Use gradient checking to verify the correctness of your backpropagation implementation
   - [Week 2: Optimization algorithms]()
     + Remember different optimization method such as (Stochastic) Gradient Descent, Momentum, RMSProp and Adam
     + Use random minibatches to accelerate the convergence and improve the optimization
     + Know the benefit of learning rate decay and apply it on your optimization
  - [Week 3: Hyperparameter tuning]()
     + Master the process of hyperparameter tuning

**Programming Assignments**

### Course 3: Structuring Machine Learning Projects

**Topics Covered**
  - [Week 1: ML Strategy (1)]()
    + Understand why Machine Learning strategy is important
    + Apply satisfying and optimizing metrics to set up your goal for ML projects
    + Choose a correct train/dev/test split of your dataset
    + Understand how to define human-level performance
    + Use human-level perform to define your key priorities in ML projects
    + Take the correct ML Strategic decision based on observations of performances and dataset
  - [Week 2: ML Strategy (2)]()
    + Understand what multi-task learning and transfer learning are
    + Recognize bias, variance and data-mismatch by looking at the performances of your algorithm on train/dev/test sets

**Programming Assignments**

### Course 4: Convolutional Neural Networks

**Topics Covered**
  - [Week 1: Foundations of Convolutional Neural Networks]()
    + Understand the convolution operation
    + Understand the pooling operation
    + Remember the vocabulary used in convolutional neural network (padding, stride, filter, ...)
    + Build a convolutional neural network for image multi-class classification
  - [Week 2: Deep convolutional models: case studies]()
    + Understand multiple foundational papers of convolutional neural networks
    + Analyze the dimensionality reduction of a volume in a very deep network
    + Understand and Implement a Residual network
    + Build a deep neural network using Keras
    + Implement a skip-connection in your network
    + Clone a repository from github and use transfer learning
  - [Week 3: Object detection]()
    + Understand the challenges of Object Localization, Object Detection and Landmark Finding
    + Understand and implement non-max suppression
    + Understand and implement intersection over union
    + Understand how we label a dataset for an object detection application
    + Remember the vocabulary of object detection (landmark, anchor, bounding box, grid, ...)
  - [Week 4: Special applications: Face recognition & Neural style transfer]()
    + Discover how CNNs can be applied to multiple fields, including art generation and face recognition.
    + Implement your own algorithm to generate art and recognize faces

**Programming Assignments**

### Course 5: Sequence Models

**Topics Covered**
  - [Week 1: Foundations of Recurrent Neural Networks]()
    + RNNs for temporal data
    + Limitations of vanilla RNN and its variants  
  - [Week 2: Natural Language Processing & Word Embeddings]()
    + Natural language processing with deep learning
    + Using word vector representations and embedding layers
    + Examples of applications are sentiment analysis, named entity recognition and machine translation.
  - [Week 3: Sequence models & Attention mechanism]()
    + Sequence models can be augmented using an attention mechanism.
    + Understanding attention algorithm 
    + Dealing with audio data and speach recognition

  **Programming Assignments**







